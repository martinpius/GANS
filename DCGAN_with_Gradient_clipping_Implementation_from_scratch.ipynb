{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGAN with Gradient clipping Implementation from scratch",
      "provenance": [],
      "authorship_tag": "ABX9TyNRbRxCZqwhZ43EX7xZR2lb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/martinpius/GANS/blob/main/DCGAN_with_Gradient_clipping_Implementation_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnjDzeu_oQVC",
        "outputId": "5c915f9c-8689-4154-ffdd-d0f82f3d7e92"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount = True)\n",
        "try:\n",
        "  COLAB = True\n",
        "  import torch\n",
        "  print(f\">>>> You are in Google CoLaB with torch version: {torch.__version__}\")\n",
        "except Exception as e:\n",
        "  print(f\">>>> {type(e)}: {e}\\n>>>> please correct {type(e)} and reload\")\n",
        "  COLAB = False\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "def time_fmt(t:float = 123.98)->float:\n",
        "  h = int(t / (60 * 60))\n",
        "  m = int(t % (60 * 60) / 60)\n",
        "  s = int(t % 60)\n",
        "  return f\"{h} hrs: {m:>02} min: {s:>05.2f} sec\"\n",
        "print(f\">>>> time formating\\tplease wait\\n>>>> time elapsed\\t{time_fmt()}\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            ">>>> You are in Google CoLaB with torch version: 1.8.1+cu101\n",
            ">>>> time formating\tplease wait\n",
            ">>>> time elapsed\t0 hrs: 02 min: 03.00 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SasR9Ioq0JD"
      },
      "source": [
        "#In this notebook we are going to train a GAN network with the gradient clipping technique from scratch.\n",
        "# This is a modification of DCGAN where the \n",
        "#Loss function is modified (BCELoss is replaced with the Wasserstein loss). Also the discriminator will be trained\n",
        "#several times in a loop before the generator at every epoch. The architecture of the network is completely similar \n",
        "#to DCGAN but without a sigmoid layer in the discriminator. "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqmzsygtsByk"
      },
      "source": [
        "#Importing necessary modules:\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from tqdm import tqdm\n",
        "import math, random, time, os, sys\n",
        "import numpy as np\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTr7vwHbwBgC"
      },
      "source": [
        "#setup the seeds for reproducability"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AqiQUZlwOhQ"
      },
      "source": [
        "seed = 1234\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9HsgvzJwgeL"
      },
      "source": [
        "#The discriminator:\n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, img_channels, d_features):\n",
        "    super(Discriminator, self).__init__()\n",
        "    self.discriminator = nn.Sequential(\n",
        "        nn.Conv2d(img_channels, d_features, kernel_size = 4, stride = 2, padding = 1),\n",
        "        nn.LeakyReLU(0.2),\n",
        "        self.__dblock__(d_features, 2*d_features, 4, 2, 1),\n",
        "        self.__dblock__(2*d_features, 4*d_features, 4, 2, 1),\n",
        "        self.__dblock__(4*d_features, 8*d_features, 4, 2, 1),\n",
        "        nn.Conv2d(8*d_features, 1, kernel_size = 4, stride = 1, padding = 0))\n",
        "    \n",
        "  def __dblock__(self, in_channels, out_channels, kernel_size, stride, padding):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels,\n",
        "                  out_channels,\n",
        "                  kernel_size,\n",
        "                  stride,\n",
        "                  padding,\n",
        "                  bias = False),\n",
        "                  nn.BatchNorm2d(out_channels),\n",
        "                  nn.LeakyReLU(0.2))\n",
        "  \n",
        "  def forward(self, input_tensor):\n",
        "    return self.discriminator(input_tensor)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exky5CC-7vkO"
      },
      "source": [
        "#The generator:\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self, img_channels, z_dim, g_features):\n",
        "    super(Generator, self).__init__()\n",
        "    self.generator = nn.Sequential(\n",
        "        self.__gblock__(z_dim, 16*g_features, kernel_size = 4, stride = 2, padding = 0),\n",
        "        self.__gblock__(16*g_features, 8*g_features, kernel_size = 4, stride = 2,padding = 1),\n",
        "        self.__gblock__(8*g_features, 4*g_features, kernel_size = 4, stride = 2, padding = 1),\n",
        "        self.__gblock__(4*g_features, 2*g_features, kernel_size = 4, stride = 2, padding = 1),\n",
        "        nn.ConvTranspose2d(2*g_features, img_channels, kernel_size = 4, stride = 2, padding = 1),\n",
        "        nn.Tanh())\n",
        "\n",
        "  def __gblock__(self, in_channels, out_channels, kernel_size, stride, padding):\n",
        "    return nn.Sequential(\n",
        "        nn.ConvTranspose2d(in_channels,\n",
        "                           out_channels,\n",
        "                           kernel_size,\n",
        "                           stride,\n",
        "                           padding, bias = False),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU())\n",
        "  \n",
        "  def forward(self, input_tensor):\n",
        "    return self.generator(input_tensor)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NV2_OHAG-0Sy"
      },
      "source": [
        "#Testing the classes if they deliver the desired outputs\n",
        "def __test__():\n",
        "  H, W,img_channels = 64, 64, 3\n",
        "  z_dim = 100\n",
        "  batch_size = 64\n",
        "  fake_img = torch.randn(batch_size,img_channels,W,H)# for the discriminator\n",
        "  noise_img = torch.randn(batch_size, z_dim, 1, 1) #for the generator\n",
        "  disc = Discriminator(img_channels, 8)#instantiate the discriminator network\n",
        "  gen = Generator(img_channels, z_dim, 8)#instantiating the generator network\n",
        "  disc_out = disc(fake_img)#shape expected [batch_size, 1, 1, 1]\n",
        "  gen_out = gen(noise_img)# shape expected [batch_size, img_channels, W,H]\n",
        "  return f\"gen_out_shape: {gen_out.shape}\\tdisc_out_shape: {disc_out.shape}\""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "uN4wBNjrB2ZZ",
        "outputId": "53efb038-5f10-4c24-e5f8-2b24d23d8533"
      },
      "source": [
        "__test__()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'gen_out_shape: torch.Size([64, 3, 64, 64])\\tdisc_out_shape: torch.Size([64, 1, 1, 1])'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8cysxP8B4rF"
      },
      "source": [
        "#weight initializer(we initialize the weight to random normal with mean 0 and std 0.01)\n",
        "def __initializer__(model):\n",
        "  for m in model.modules():\n",
        "    if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n",
        "      nn.init.normal_(m.weight.data, mean = 0.00, std = 0.01)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3nM-pSaFNea",
        "outputId": "dfe0312c-ee6b-4011-cfa0-08d62527294e"
      },
      "source": [
        "#Hyperparameters:\n",
        "batch_size = 128\n",
        "EPOCHS = 10\n",
        "disc_iter = 5\n",
        "wt_clip = 0.01\n",
        "learning_rate = 5e-5\n",
        "d_features = 64\n",
        "g_features = 64\n",
        "img_size = 64\n",
        "img_channels = 1\n",
        "z_dim = 100\n",
        "fixed_noise = torch.randn(batch_size, z_dim, 1, 1).to(device = device)\n",
        "discriminator = Discriminator(img_channels, d_features).to(device = device)\n",
        "generator = Generator(img_channels, z_dim, g_features).to(device = device)\n",
        "__initializer__(discriminator)\n",
        "__initializer__(generator)\n",
        "print(f\">>>> discriminator network:\\n{discriminator}\")\n",
        "print(f\"\\n\\n>>>> generator network:\\n{generator}\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>>> discriminator network:\n",
            "Discriminator(\n",
            "  (discriminator): Sequential(\n",
            "    (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (1): LeakyReLU(negative_slope=0.2)\n",
            "    (2): Sequential(\n",
            "      (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (3): Sequential(\n",
            "      (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (4): Sequential(\n",
            "      (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (5): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1))\n",
            "  )\n",
            ")\n",
            "\n",
            "\n",
            ">>>> generator network:\n",
            "Generator(\n",
            "  (generator): Sequential(\n",
            "    (0): Sequential(\n",
            "      (0): ConvTranspose2d(100, 1024, kernel_size=(4, 4), stride=(2, 2), bias=False)\n",
            "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (2): Sequential(\n",
            "      (0): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (3): Sequential(\n",
            "      (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (4): ConvTranspose2d(128, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (5): Tanh()\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnsL1NfhHnwD"
      },
      "source": [
        "#Loading and preprocess the data from torchvision:"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_GIYDBXQpw8"
      },
      "source": [
        "transforms = transforms.Compose([transforms.ToTensor(), transforms.Resize(img_size),\n",
        "    transforms.Normalize([0.5 for _ in range(img_channels)],[0.5 for _ in range(img_channels)])])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6lBe6OlRzVq",
        "outputId": "423c7d40-0a74-40f8-f93b-9314b2bfb246"
      },
      "source": [
        "dfm = datasets.MNIST(root = \"mnist/\", transform = transforms, download = True,)\n",
        "loader = DataLoader(dfm, batch_size = batch_size, shuffle = True)\n",
        "x_dfm, y_dfm = next(iter(loader))\n",
        "print(f\"x_dfm_shape: {x_dfm.shape}\\ty_dfm_shape: {y_dfm.shape}\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_dfm_shape: torch.Size([128, 1, 64, 64])\ty_dfm_shape: torch.Size([128])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5g0AnO9_SV89",
        "outputId": "c4fe3cc9-c721-4b4f-d139-c4f7219321e0"
      },
      "source": [
        "step = 0\n",
        "real_writer = SummaryWriter(f\"runs/real_images\")\n",
        "fake_writer = SummaryWriter(f\"runs/fake_images\")\n",
        "disc_opt = optim.RMSprop(params = discriminator.parameters(), lr = learning_rate)\n",
        "gen_opt = optim.RMSprop(params = generator.parameters(), lr = learning_rate)\n",
        "global_tic = time.time()\n",
        "for epoch in range(EPOCHS):\n",
        "  tic = time.time()\n",
        "  print(f\"\\n>>>> training begins for epoch {epoch+1}\\nplease wait while the model is training........\")\n",
        "  for idx, (real, _) in enumerate(tqdm(loader)):\n",
        "    real = real.to(device = device)\n",
        "    #training the discriminator (in a loop of 5 iterations)\n",
        "    for _ in range(disc_iter):\n",
        "      fake = torch.randn(batch_size, z_dim, 1, 1).to(device)\n",
        "      noise = generator(fake)\n",
        "      real_disc_out = discriminator(real).reshape(-1) #flattening to 1d\n",
        "      fake_disc_out = discriminator(noise).reshape(-1)#flattening to 1d\n",
        "      disc_loss = -(torch.mean(real_disc_out) - torch.mean(fake_disc_out))\n",
        "      discriminator.zero_grad()\n",
        "      disc_loss.backward(retain_graph = True)\n",
        "      disc_opt.step()\n",
        "      #clipping the gradients\n",
        "      for m in discriminator.parameters():\n",
        "        m.data.clamp_(-wt_clip, wt_clip)\n",
        "\n",
        "      #training the generator (max (log(D(G(z)))))\n",
        "      gen_out = discriminator(noise).reshape(-1)\n",
        "      gen_loss = -torch.mean(gen_out)\n",
        "      generator.zero_grad()\n",
        "      gen_loss.backward()\n",
        "      gen_opt.step()\n",
        "      toc = time.time()\n",
        "      if idx % 200 == 0:\n",
        "        print(f\"\\n>>>> time at the end of epoch {epoch +1} of batch {idx} is {time_fmt(toc - tic)}\")\n",
        "        print(f\">>>> generator Loss: {gen_loss:.4f} | Generator PPL: {math.exp(gen_loss):7.4f}\")\n",
        "        print(f\">>>> discriminator loss: {disc_loss:.4f} | discriminator PPL: {math.exp(disc_loss):7.4f}\")\n",
        "        #fetching and printing the fake and real images to tensorboard\n",
        "        with torch.no_grad():\n",
        "          fake_images = generator(fixed_noise).to(device)\n",
        "          fake_grid = torchvision.utils.make_grid(fake_images[:32], normalize = True)\n",
        "          real_grid = torchvision.utils.make_grid(real[:32], normalize = True)\n",
        "          real_writer.add_image('real_image', real_grid, global_step = step)\n",
        "          fake_writer.add_image('fake_image', fake_grid, global_step = step)\n",
        "        step += 1\n",
        "gloabal_toc = time.time()\n",
        "print(f\"\\n>>>> total time elapsed for 10 iterations is: {time_fmt(gloabal_toc - global_tic)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            ">>>> training begins for epoch 1\n",
            "please wait while the model is training........\n",
            "\n",
            ">>>> time at the end of epoch 1 of batch 0 is 0 hrs: 00 min: 19.00 sec\n",
            ">>>> generator Loss: -0.0024 | Generator PPL:  0.9976\n",
            ">>>> discriminator loss: -0.0098 | discriminator PPL:  0.9903\n",
            "\n",
            ">>>> time at the end of epoch 1 of batch 0 is 0 hrs: 00 min: 42.00 sec\n",
            ">>>> generator Loss: 0.0047 | Generator PPL:  1.0047\n",
            ">>>> discriminator loss: -0.0528 | discriminator PPL:  0.9486\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gdrr5Q-_kCkn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}